{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDDç»ƒä¹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/18 08:33:23 WARN Utils: Your hostname, ubuntu-linux-22-04-desktop resolves to a loopback address: 127.0.1.1; using 10.211.55.3 instead (on interface enp0s5)\n",
      "23/05/18 08:33:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/18 08:33:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "3.3.2\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "import pyspark \n",
    "from pyspark import SparkContext, SparkConf\n",
    "#æŒ‡å®šspark_homeä¸ºåˆšæ‰çš„è§£å‹è·¯å¾„,æŒ‡å®špythonè·¯å¾„\n",
    "spark_home = \"/home/parallels/Desktop/work/spark-3.3.2-bin-hadoop3\"\n",
    "python_path = \"/home/parallels/anaconda3/bin/python3\"\n",
    "findspark.init(spark_home,python_path)\n",
    "\n",
    "conf = SparkConf().setAppName(\"test\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ã€æ±‚å¹³å‡æ•°\n",
    "ä»»åŠ¡ï¼šæ±‚dataçš„å¹³å‡å€¼\n",
    "data = [1,5,7,10,23,20,6,5,10,7,10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æˆ‘çš„è§£æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.454545454545455\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,5,7,10,23,20,6,5,10,7,10])\n",
    "sum = sc.accumulator(0)\n",
    "count = sc.accumulator(0)\n",
    "\n",
    "def get_average(x):\n",
    "    sum.add(x)\n",
    "    count.add(1)\n",
    "\n",
    "rdd.foreach(get_average)\n",
    "print(sum.value/count.value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç­”æ¡ˆ\n",
    "æ€ä¹ˆæ²¡æˆ‘çš„å¿«ï¼ŸğŸ¤•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 9.454545454545455\n"
     ]
    }
   ],
   "source": [
    "#ä»»åŠ¡ï¼šæ±‚dataçš„å¹³å‡å€¼\n",
    "data = [1,5,7,10,23,20,6,5,10,7,10]\n",
    "\n",
    "rdd_data = sc.parallelize(data)\n",
    "s = rdd_data.reduce(lambda x,y:x+y+0.0)\n",
    "n = rdd_data.count()\n",
    "avg = s/n\n",
    "print(\"average:\",avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ã€æ±‚ä¼—æ•°\n",
    "ä»»åŠ¡ï¼šæ±‚dataä¸­å‡ºç°æ¬¡æ•°æœ€å¤šçš„æ•°\n",
    "data =  [1,5,7,10,23,20,7,5,10,7,10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æˆ‘çš„è§£æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡ºç°æ¬¡æ•°æœ€å¤šçš„æ•°å­—æ˜¯ï¼š 8.5\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "rdd = sc.parallelize([1,5,7,10,23,20,7,5,10,7,10])\n",
    "max_rdd = rdd.map(lambda x: (x,1)).reduceByKey(add).sortBy(lambda x: x[1],False)\n",
    "max_num = max_rdd.first()[1]\n",
    "result = max_rdd.filter(lambda x: x[1] == max_num).map(lambda x: x[0]).collect()\n",
    "count = 0\n",
    "sum = 0\n",
    "for i in result:\n",
    "    count += 1\n",
    "    sum += i\n",
    "print(\"å‡ºç°æ¬¡æ•°æœ€å¤šçš„æ•°å­—æ˜¯ï¼š\",sum/count)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: 8.5\n"
     ]
    }
   ],
   "source": [
    "data =  [1,5,7,10,23,20,7,5,10,7,10]\n",
    "\n",
    "rdd_data = sc.parallelize(data)\n",
    "rdd_count = rdd_data.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y)\n",
    "max_count = rdd_count.map(lambda x:x[1]).reduce(lambda x,y: x if x>=y else y)\n",
    "rdd_mode = rdd_count.filter(lambda x:x[1]==max_count).map(lambda x:x[0])\n",
    "mode = rdd_mode.reduce(lambda x,y:x+y+0.0)/rdd_mode.count()\n",
    "print(\"mode:\",mode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ã€æ±‚TopN\n",
    "ä»»åŠ¡ï¼šæœ‰ä¸€æ‰¹å­¦ç”Ÿä¿¡æ¯è¡¨æ ¼ï¼ŒåŒ…æ‹¬name,age,score, æ‰¾å‡ºscoreæ’åå‰3çš„å­¦ç”Ÿ, scoreç›¸åŒå¯ä»¥ä»»å–\n",
    "students = [(\"LiLei\",18,87),(\"HanMeiMei\",16,77),(\"DaChui\",16,66),(\"Jim\",18,77),(\"RuHua\",18,50)]\n",
    "n = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æˆ‘çš„è§£æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LiLei', 18, 87), ('HanMeiMei', 16, 77), ('Jim', 18, 77)]\n"
     ]
    }
   ],
   "source": [
    "students = [(\"LiLei\",18,87),(\"HanMeiMei\",16,77),(\"DaChui\",16,66),(\"Jim\",18,77),(\"RuHua\",18,50)]\n",
    "n = 3\n",
    "\n",
    "def getTopN(students,n):\n",
    "    rdd = sc.parallelize(students)\n",
    "    sort_rdd = rdd.sortBy(lambda x:x[2],False)\n",
    "    topN = sort_rdd.take(n)\n",
    "    return topN\n",
    "\n",
    "print(getTopN(students,n))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LiLei', 18, 87), ('HanMeiMei', 16, 77), ('Jim', 18, 77)]\n"
     ]
    }
   ],
   "source": [
    "students = [(\"LiLei\",18,87),(\"HanMeiMei\",16,77),(\"DaChui\",16,66),(\"Jim\",18,77),(\"RuHua\",18,50)]\n",
    "n = 3\n",
    "\n",
    "rdd_students = sc.parallelize(students)\n",
    "rdd_sorted = rdd_students.sortBy(lambda x:x[2],ascending = False)\n",
    "\n",
    "students_topn = rdd_sorted.take(n)\n",
    "print(students_topn)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ã€æ’åºå¹¶è¿”å›åºå·\n",
    "ä»»åŠ¡ï¼šæ’åºå¹¶è¿”å›åºå·, å¤§å°ç›¸åŒçš„åºå·å¯ä»¥ä¸åŒ\n",
    "data = [1,7,8,5,3,18,34,9,0,12,8]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æˆ‘çš„è§£æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 1),\n",
       " (2, 3),\n",
       " (3, 5),\n",
       " (4, 7),\n",
       " (5, 8),\n",
       " (6, 8),\n",
       " (7, 9),\n",
       " (8, 12),\n",
       " (9, 18),\n",
       " (10, 34)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1,7,8,5,3,18,34,9,0,12,8]\n",
    "\n",
    "rdd = sc.parallelize(data)\n",
    "rdd.sortBy(lambda x:x).zipWithIndex().map(lambda x: (x[1],x[0])).collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ä»»åŠ¡ï¼šæŒ‰ä»å°åˆ°å¤§æ’åºå¹¶è¿”å›åºå·, å¤§å°ç›¸åŒçš„åºå·å¯ä»¥ä¸åŒ\n",
    "data = [1,7,8,5,3,18,34,9,0,12,8]\n",
    "\n",
    "rdd_data = sc.parallelize(data)\n",
    "rdd_sorted = rdd_data.map(lambda x:(x,1)).sortByKey().map(lambda x:x[0])\n",
    "rdd_sorted_index = rdd_sorted.zipWithIndex()\n",
    "\n",
    "print(rdd_sorted_index.collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ã€äºŒæ¬¡æ’åº\n",
    "ä»»åŠ¡ï¼šæœ‰ä¸€æ‰¹å­¦ç”Ÿä¿¡æ¯è¡¨æ ¼ï¼ŒåŒ…æ‹¬name,age,score\n",
    "é¦–å…ˆæ ¹æ®å­¦ç”Ÿçš„scoreä»å¤§åˆ°å°æ’åºï¼Œå¦‚æœscoreç›¸åŒï¼Œæ ¹æ®ageä»å¤§åˆ°å°\n",
    "students = [(\"LiLei\",18,87),(\"HanMeiMei\",16,77),(\"DaChui\",16,66),(\"Jim\",18,77),(\"RuHua\",18,50)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æˆ‘çš„è§£æ³•ï¼ˆâŒï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = [(\"LiLei\",18,87),(\"HanMeiMei\",16,77),(\"DaChui\",16,66),(\"Jim\",18,77),(\"RuHua\",18,50)]\n",
    "rdd = sc.parallelize(students)\n",
    "rdd.sortBy(lambda x:x[2],False).sortBy(lambda x:[x[1]]).collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ä»»åŠ¡ï¼šæœ‰ä¸€æ‰¹å­¦ç”Ÿä¿¡æ¯è¡¨æ ¼ï¼ŒåŒ…æ‹¬name,age,score\n",
    "#é¦–å…ˆæ ¹æ®å­¦ç”Ÿçš„scoreä»å¤§åˆ°å°æ’åºï¼Œå¦‚æœscoreç›¸åŒï¼Œæ ¹æ®ageä»å¤§åˆ°å°\n",
    "\n",
    "students = [(\"LiLei\",18,87),(\"HanMeiMei\",16,77),(\"DaChui\",16,66),(\"Jim\",18,77),(\"RuHua\",18,50)]\n",
    "rdd_students = sc.parallelize(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing student.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile student.py\n",
    "#ä¸ºäº†åœ¨RDDä¸­ä½¿ç”¨è‡ªå®šä¹‰ç±»ï¼Œéœ€è¦å°†ç±»çš„åˆ›å»ºä»£ç å…¶å†™å…¥åˆ°ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œå¦åˆ™ä¼šæœ‰åºåˆ—åŒ–é”™è¯¯\n",
    "class Student:\n",
    "    def __init__(self,name,age,score):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.score = score\n",
    "    def __gt__(self,other):\n",
    "        if self.score > other.score:\n",
    "            return True\n",
    "        elif self.score==other.score and self.age>other.age:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LiLei', 18, 87),\n",
       " ('Jim', 18, 77),\n",
       " ('HanMeiMei', 16, 77),\n",
       " ('DaChui', 16, 66),\n",
       " ('RuHua', 18, 50)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from student import Student\n",
    "\n",
    "rdd_sorted = rdd_students \\\n",
    "    .map(lambda t:Student(t[0],t[1],t[2]))\\\n",
    "    .sortBy(lambda x:x,ascending = False)\\\n",
    "    .map(lambda student:(student.name,student.age,student.score))\n",
    "\n",
    "#å‚è€ƒæ–¹æ¡ˆï¼šæ­¤å¤„å·§å¦™åœ°å¯¹scoreå’Œageè¿›è¡Œç¼–ç æ¥è¡¨è¾¾å…¶æ’åºä¼˜å…ˆçº§å…³ç³»ï¼Œé™¤éageè¶…è¿‡100000ï¼Œä»¥ä¸‹é€»è¾‘æ— é”™è¯¯ã€‚\n",
    "#rdd_sorted = rdd_students.sortBy(lambda x:100000*x[2]+x[1],ascending=False)\n",
    "\n",
    "rdd_sorted.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ã€è¿æ¥æ“ä½œ\n",
    "ä»»åŠ¡ï¼šå·²çŸ¥ç­çº§ä¿¡æ¯è¡¨å’Œæˆç»©è¡¨ï¼Œæ‰¾å‡ºç­çº§å¹³å‡åˆ†åœ¨75åˆ†ä»¥ä¸Šçš„ç­çº§\n",
    "ç­çº§ä¿¡æ¯è¡¨åŒ…æ‹¬class,name,æˆç»©è¡¨åŒ…æ‹¬name,score\n",
    "\n",
    "classes = [(\"class1\",\"LiLei\"), (\"class1\",\"HanMeiMei\"),(\"class2\",\"DaChui\"),(\"class2\",\"RuHua\")]\n",
    "scores = [(\"LiLei\",76),(\"HanMeiMei\",80),(\"DaChui\",70),(\"RuHua\",60)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æˆ‘çš„è§£æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class2', <pyspark.resultiterable.ResultIterable at 0xffff683e0c10>),\n",
       " ('class1', <pyspark.resultiterable.ResultIterable at 0xffff683fad40>)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [(\"class1\",\"LiLei\"), (\"class1\",\"HanMeiMei\"),(\"class2\",\"DaChui\"),(\"class2\",\"RuHua\")]\n",
    "scores = [(\"LiLei\",76),(\"HanMeiMei\",80),(\"DaChui\",70),(\"RuHua\",60)]\n",
    "rdd_classes = sc.parallelize(classes).map(lambda x:(x[1],x[0]))\n",
    "rdd_scores = sc.parallelize(scores)\n",
    "rdd_join = rdd_classes.join(rdd_scores).groupBy(lambda x:x[1][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('class1', 78.0)]\n"
     ]
    }
   ],
   "source": [
    "#ä»»åŠ¡ï¼šå·²çŸ¥ç­çº§ä¿¡æ¯è¡¨å’Œæˆç»©è¡¨ï¼Œæ‰¾å‡ºç­çº§å¹³å‡åˆ†åœ¨75åˆ†ä»¥ä¸Šçš„ç­çº§\n",
    "#ç­çº§ä¿¡æ¯è¡¨åŒ…æ‹¬class,name,æˆç»©è¡¨åŒ…æ‹¬name,score\n",
    "\n",
    "classes = [(\"class1\",\"LiLei\"), (\"class1\",\"HanMeiMei\"),(\"class2\",\"DaChui\"),(\"class2\",\"RuHua\")]\n",
    "scores = [(\"LiLei\",76),(\"HanMeiMei\",80),(\"DaChui\",70),(\"RuHua\",60)]\n",
    "\n",
    "rdd_classes = sc.parallelize(classes).map(lambda x:(x[1],x[0]))\n",
    "rdd_scores = sc.parallelize(scores)\n",
    "rdd_join = rdd_scores.join(rdd_classes).map(lambda t:(t[1][1],t[1][0]))\n",
    "\n",
    "def average(iterator):\n",
    "    data = list(iterator)\n",
    "    s = 0.0\n",
    "    for x in data:\n",
    "        s = s + x\n",
    "    return s/len(data)\n",
    "\n",
    "rdd_result = rdd_join.groupByKey().map(lambda t:(t[0],average(t[1]))).filter(lambda t:t[1]>75)\n",
    "print(rdd_result.collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ã€åˆ†ç»„æ±‚ä¼—æ•°\n",
    "ä»»åŠ¡ï¼šæœ‰ä¸€æ‰¹å­¦ç”Ÿä¿¡æ¯è¡¨æ ¼ï¼ŒåŒ…æ‹¬classå’Œageã€‚æ±‚æ¯ä¸ªç­çº§å­¦ç”Ÿå¹´é¾„çš„ä¼—æ•°ã€‚\n",
    "students = [(\"class1\",15),(\"class1\",15),(\"class2\",16),(\"class2\",16),(\"class1\",17),(\"class2\",19)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æˆ‘çš„è§£æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class1', 15), ('class2', 16)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "students = [(\"class1\",15),(\"class1\",15),(\"class2\",16),(\"class2\",16),(\"class1\",17),(\"class2\",19)]\n",
    "rdd = sc.parallelize(students)\n",
    "rdd_group = rdd.groupByKey().map(lambda x: (x,1)).reduceByKey(add)\n",
    "# .map(lambda t:(t[0],list(t[1])))\n",
    "\n",
    "def getMostNum(iterator):\n",
    "    data = list(iterator)\n",
    "    # æ±‚ä¼—æ•°\n",
    "    \n",
    "\n",
    "    # data.sort(reverse=True)\n",
    "    # count = 0\n",
    "    # most_num = data[0]\n",
    "    # for x in data:\n",
    "    #     if x == most_num:\n",
    "    #         count = count + 1\n",
    "    #     else:\n",
    "    #         count = 1\n",
    "    #         most_num = x\n",
    "    # return most_num\n",
    "rdd_group.map(lambda t:(t[0],getMostNum(t[1]))).collect()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('class1', 15.0), ('class2', 16.0)]\n"
     ]
    }
   ],
   "source": [
    "students = [(\"class1\",15),(\"class1\",15),(\"class2\",16),(\"class2\",16),(\"class1\",17),(\"class2\",19)]\n",
    "def mode(arr):\n",
    "    dict_cnt = {}\n",
    "    for x in arr:\n",
    "        dict_cnt[x] = dict_cnt.get(x,0)+1\n",
    "    max_cnt = max(dict_cnt.values())\n",
    "    most_values = [k for k,v in dict_cnt.items() if v==max_cnt]\n",
    "    s = 0.0\n",
    "    for x in most_values:\n",
    "        s = s + x\n",
    "    return s/len(most_values)\n",
    "\n",
    "rdd_students = sc.parallelize(students)\n",
    "rdd_classes = rdd_students.aggregateByKey([],lambda arr,x:arr+[x],lambda arr1,arr2:arr1+arr2)\n",
    "rdd_mode = rdd_classes.map(lambda t:(t[0],mode(t[1])))\n",
    "\n",
    "print(rdd_mode.collect())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f46a25d2ee2cf42d8b5967fa87ecb381310ee627e58dce25c5456af41f27dd69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
